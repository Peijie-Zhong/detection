{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch \n",
    "import logging\n",
    "import numpy as np\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch\n",
    "\n",
    "\n",
    "\n",
    "def l_modularity_loss(assignments, events, degrees, mu):\n",
    "    \"\"\"\n",
    "    L-Modularity loss with proper normalization.\n",
    "\n",
    "    assignments: Tensor of shape (N, T, K)\n",
    "        Soft community assignments h_u(t), sum to 1 over K.\n",
    "    events: LongTensor of shape (E, 4)\n",
    "        Each row [idx, i, j, t] is an event between i and j at time t.\n",
    "    degrees: Tensor of shape (N,)\n",
    "        Node degrees k_u over the entire link stream.\n",
    "    m: float\n",
    "        Total number of (undirected) events: m = |E|.\n",
    "    mu: float\n",
    "        Weight of the smoothness penalty.\n",
    "\n",
    "    Returns:\n",
    "        loss: Scalar Tensor = −Q_norm + mu * smoothness_norm,\n",
    "              where Q_norm ∈ [−1,1] and smoothness_norm ∈ [0,1].\n",
    "    \"\"\"\n",
    "    N, T, K = assignments.shape\n",
    "    E = events.shape[0]\n",
    "\n",
    "    # --- 1) Observed co-membership at each event ---\n",
    "    i_idx, j_idx, t_idx = events[:,1], events[:,2], events[:,3]\n",
    "    h_i = assignments[i_idx, t_idx]   # (E, K)\n",
    "    h_j = assignments[j_idx, t_idx]   # (E, K)\n",
    "    obs = (h_i * h_j).sum(dim=1)      # (E,)\n",
    "    # Sum over all events, then normalize by 2m as in static modularity\n",
    "    observed_sum = obs.sum() \n",
    "\n",
    "    # --- 2) Expected co-membership under longitudinal null model ---\n",
    "    # Get degrees for each event\n",
    "    deg_i = degrees[i_idx].float().to(assignments.device)\n",
    "    deg_j = degrees[j_idx].float().to(assignments.device)\n",
    "    # Per-event expected co-membership: (k_i k_j)/(2m) * avg_t [h_i(t)·h_j(t)]\n",
    "    # First compute avg_t dot products over all T time points:\n",
    "    h_i_all = assignments[i_idx]      # (E, T, K)\n",
    "    h_j_all = assignments[j_idx]      # (E, T, K)\n",
    "    dots = (h_i_all * h_j_all).sum(dim=2)  # (E, T)\n",
    "    avg_dot = dots.mean(dim=1)            # (E,)\n",
    "    expct = (deg_i * deg_j / (2 * E)) * avg_dot  # (E,)\n",
    "    expected_sum = expct.sum()\n",
    "\n",
    "    # --- 3) Normalized modularity score Q ∈ [−1,1] ---\n",
    "    Q_norm = (observed_sum - expected_sum) / (2 * E)\n",
    "\n",
    "    # --- 4) Smoothness penalty: squared L2 jumps between t and t+1 ---\n",
    "    diffs = assignments[:, 1:, :] - assignments[:, :-1, :]  # (N, T-1, K)\n",
    "    smooth = diffs.pow(2).sum()  # maximum is 2 * N * (T-1)\n",
    "    # Normalize by the maximal possible jump sum\n",
    "    smoothness_norm = smooth / (N * (T - 1))\n",
    "\n",
    "    # --- 5) Final loss: minimize negative modularity + mu * smoothness ---\n",
    "    loss = -Q_norm + mu * smoothness_norm\n",
    "    return loss, Q_norm, smoothness_norm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[[0.3925, 0.6075],\n",
      "         [0.4012, 0.5988]],\n",
      "\n",
      "        [[0.3265, 0.6735],\n",
      "         [0.3535, 0.6465]],\n",
      "\n",
      "        [[0.4188, 0.5812],\n",
      "         [0.4648, 0.5352]]])\n",
      "归一化后的 L-Modularity Loss = -0.014360\n",
      "Q_norm = 0.016306\n",
      "smoothness_norm = 0.001947\n"
     ]
    }
   ],
   "source": [
    "N, T, K = 3, 2, 2\n",
    "\n",
    "# Soft assignments 随机初始化并做归一化\n",
    "torch.manual_seed(0)\n",
    "raw = torch.rand(N, T, K)\n",
    "assignments = raw / raw.sum(dim=2, keepdim=True)\n",
    "\n",
    "# 4 条交互事件：(dummy_index, i, j, t)\n",
    "# 这里 dummy_index 不影响计算，仅为兼容原数据格式\n",
    "events = torch.tensor([\n",
    "    [0, 0, 1, 0],\n",
    "    [1, 1, 2, 0],\n",
    "    [2, 0, 2, 1],\n",
    "    [3, 1, 2, 1],\n",
    "], dtype=torch.long)\n",
    "\n",
    "# 度数 k_u：简单取每个节点参与事件次数\n",
    "degrees = torch.tensor([2, 3, 3], dtype=torch.float)\n",
    "\n",
    "# 事件总数 m (无向)：4\n",
    "m = 4.0\n",
    "\n",
    "# 平滑惩罚权重\n",
    "mu = 1\n",
    "print(assignments)\n",
    "# 计算 loss\n",
    "loss, Q, smoothness = l_modularity_loss(assignments, events, degrees, mu)\n",
    "print(f\"归一化后的 L-Modularity Loss = {loss.item():.6f}\")\n",
    "print(f\"Q_norm = {Q.item():.6f}\")\n",
    "print(f\"smoothness_norm = {smoothness.item():.6f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Updated memory shape: torch.Size([3, 128])\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "\n",
    "class MemoryModule(nn.Module):\n",
    "    \"\"\"\n",
    "    A simplified TGN-style Memory module that:\n",
    "    - Holds a per-node memory tensor of shape (num_nodes, memory_dim)\n",
    "    - Updates memory via a GRUCell given aggregated messages per node\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self, num_nodes: int, memory_dim: int, msg_dim: int):\n",
    "        super().__init__()\n",
    "        self.num_nodes = num_nodes\n",
    "        self.memory_dim = memory_dim\n",
    "        \n",
    "        # Initialize memory for all nodes (num_nodes x memory_dim)\n",
    "        self.register_buffer('memory', torch.zeros(num_nodes, memory_dim))\n",
    "        \n",
    "        # Initialize last_update timestamps for all nodes (num_nodes,)\n",
    "        self.register_buffer('last_update', torch.zeros(num_nodes, dtype=torch.long))\n",
    "        \n",
    "        # GRUCell for updating memory: input is msg_dim, hidden is memory_dim\n",
    "        self.gru = nn.GRUCell(input_size=msg_dim, hidden_size=memory_dim)\n",
    "        \n",
    "    def forward(self, node_ids: torch.LongTensor, msgs: torch.Tensor, timestamps: torch.LongTensor):\n",
    "        \"\"\"\n",
    "        Update memory for the given nodes based on their aggregated messages.\n",
    "        \n",
    "        Args:\n",
    "            node_ids: LongTensor of shape (B,) with node indices in this batch.\n",
    "            msgs: Tensor of shape (B, msg_dim) with aggregated message per node.\n",
    "            timestamps: LongTensor of shape (B,) with event timestamps per message.\n",
    "        \"\"\"\n",
    "        # Gather old memory for these nodes\n",
    "        old_mem = self.memory[node_ids]           # (B, memory_dim)\n",
    "        \n",
    "        # Update memory via GRUCell\n",
    "        new_mem = self.gru(msgs, old_mem)         # (B, memory_dim)\n",
    "        \n",
    "        # Write back updated memory\n",
    "        self.memory[node_ids] = new_mem\n",
    "        \n",
    "        # Update last_update timestamps\n",
    "        self.last_update[node_ids] = timestamps\n",
    "        \n",
    "        return new_mem\n",
    "\n",
    "# Example usage:\n",
    "num_nodes = 1000\n",
    "memory_dim = 128\n",
    "msg_dim = 64\n",
    "\n",
    "memory_module = MemoryModule(num_nodes, memory_dim, msg_dim)\n",
    "\n",
    "# Suppose batch of 3 nodes with aggregated messages and timestamps\n",
    "batch_node_ids = torch.tensor([5, 20, 500])\n",
    "aggregated_msgs = torch.randn(3, msg_dim)\n",
    "batch_times = torch.tensor([100, 100, 100], dtype=torch.long)\n",
    "\n",
    "# Forward pass updates memory in-place\n",
    "updated_memory = memory_module(batch_node_ids, aggregated_msgs, batch_times)\n",
    "print(\"Updated memory shape:\", updated_memory.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch \n",
    "import logging\n",
    "import numpy as np\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch\n",
    "\n",
    "\n",
    "class MergeLayer(torch.nn.Module):\n",
    "    def __init__(self, dim1, dim2, dim3, dim4):\n",
    "        super().__init__()\n",
    "        #self.layer_norm = torch.nn.LayerNorm(dim1 + dim2)\n",
    "        self.fc1 = torch.nn.Linear(dim1 + dim2, dim3)\n",
    "        self.fc2 = torch.nn.Linear(dim3, dim4)\n",
    "        self.act = torch.nn.ReLU()\n",
    "        torch.nn.init.xavier_normal_(self.fc1.weight)\n",
    "        torch.nn.init.xavier_normal_(self.fc2.weight)\n",
    "\n",
    "    def forward(self, x1, x2):\n",
    "        x = torch.cat([x1, x2], dim=1)\n",
    "        h = self.act(self.fc1(x))\n",
    "        return self.fc2(h)\n",
    "\n",
    "\n",
    "class CommunityLayer(nn.Module):\n",
    "    def __init__(self, input_dim, hidden_dim, num_communities):\n",
    "        super(CommunityLayer, self).__init__()\n",
    "        self.num_communities = num_communities\n",
    "        self.mlp = nn.Sequential(\n",
    "            nn.Linear(input_dim, hidden_dim),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(hidden_dim, hidden_dim),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(hidden_dim, num_communities)\n",
    "        )\n",
    "\n",
    "    def forward(self, node_features):\n",
    "        \"\"\"\n",
    "        node_features: Tensor (batch_size, T, D)\n",
    "        returns:\n",
    "            logits: Tensor (batch_size, T, K)\n",
    "            probs:  Tensor (batch_size, T, K)\n",
    "        \"\"\"\n",
    "        B, T, D = node_features.size()\n",
    "        feats_flat = node_features.view(B * T, D)\n",
    "        logits_flat = self.mlp(feats_flat)\n",
    "        probs_flat = F.softmax(logits_flat, dim=-1)\n",
    "        logits = logits_flat.view(B, T, self.num_communities)\n",
    "        probs  = probs_flat.view(B, T, self.num_communities)\n",
    "        return logits, probs\n",
    "\n",
    "    \n",
    "\n",
    "class LSTMPool(torch.nn.Module):\n",
    "    def __init__(self, feat_dim, time_dim):\n",
    "        super(LSTMPool, self).__init__()\n",
    "        self.feat_dim = feat_dim\n",
    "        self.time_dim = time_dim\n",
    "        self.att_dim = feat_dim + time_dim\n",
    "        self.act = torch.nn.ReLU()\n",
    "        self.lstm = torch.nn.LSTM(input_size=self.att_dim, \n",
    "                                  hidden_size=self.feat_dim, \n",
    "                                  num_layers=1, \n",
    "                                  batch_first=True)\n",
    "        self.merger = MergeLayer(feat_dim, feat_dim, feat_dim, feat_dim)\n",
    "    def forward(self, src, src_t, seq, seq_t, mask):\n",
    "        # seq [B, N, D]\n",
    "        # mask [B, N]\n",
    "        seq_x = torch.cat([seq, seq_t], dim=2)\n",
    "            \n",
    "        _, (hn, _) = self.lstm(seq_x)\n",
    "        \n",
    "        hn = hn[-1, :, :] #hn.squeeze(dim=0)\n",
    "\n",
    "        out = self.merger.forward(hn, src)\n",
    "        return out, None\n",
    "\n",
    "\n",
    "class MeanPool(torch.nn.Module):\n",
    "    def __init__(self, feat_dim):\n",
    "        super(MeanPool, self).__init__()\n",
    "        self.feat_dim = feat_dim\n",
    "        self.act = torch.nn.ReLU()\n",
    "        self.merger = MergeLayer(feat_dim, feat_dim, feat_dim, feat_dim)\n",
    "        \n",
    "    def forward(self, src, seq, seq_e):\n",
    "        # seq [B, N, D]\n",
    "        # mask [B, N]\n",
    "        src_x = src\n",
    "        seq_x = torch.cat([seq, seq_e], dim=2) #[B, N, De + D]\n",
    "        hn = seq_x.mean(dim=1) #[B, De + D]\n",
    "        output = self.merger(hn, src_x)\n",
    "        return output, None\n",
    "\n",
    "class ScaledDotProductAttention(torch.nn.Module):\n",
    "    ''' Scaled Dot-Product Attention '''\n",
    "\n",
    "    def __init__(self, temperature, attn_dropout=0.1):\n",
    "        super().__init__()\n",
    "        self.temperature = temperature\n",
    "        self.dropout = torch.nn.Dropout(attn_dropout)\n",
    "        self.softmax = torch.nn.Softmax(dim=2)\n",
    "\n",
    "    def forward(self, q, k, v, mask=None):\n",
    "\n",
    "        attn = torch.bmm(q, k.transpose(1, 2))\n",
    "        attn = attn / self.temperature\n",
    "\n",
    "        if mask is not None:\n",
    "            attn = attn.masked_fill(mask, -1e10)\n",
    "\n",
    "        attn = self.softmax(attn) # [n * b, l_q, l_k]\n",
    "        attn = self.dropout(attn) # [n * b, l_v, d]\n",
    "                \n",
    "        output = torch.bmm(attn, v)\n",
    "        \n",
    "        return output, attn\n",
    "\n",
    "class MultiHeadAttention(nn.Module):\n",
    "    ''' Multi-Head Attention module '''\n",
    "\n",
    "    def __init__(self, n_head, d_model, d_k, d_v, dropout=0.1):\n",
    "        super().__init__()\n",
    "\n",
    "        self.n_head = n_head\n",
    "        self.d_k = d_k\n",
    "        self.d_v = d_v\n",
    "\n",
    "        self.w_qs = nn.Linear(d_model, n_head * d_k, bias=False)\n",
    "        self.w_ks = nn.Linear(d_model, n_head * d_k, bias=False)\n",
    "        self.w_vs = nn.Linear(d_model, n_head * d_v, bias=False)\n",
    "        nn.init.normal_(self.w_qs.weight, mean=0, std=np.sqrt(2.0 / (d_model + d_k)))\n",
    "        nn.init.normal_(self.w_ks.weight, mean=0, std=np.sqrt(2.0 / (d_model + d_k)))\n",
    "        nn.init.normal_(self.w_vs.weight, mean=0, std=np.sqrt(2.0 / (d_model + d_v)))\n",
    "\n",
    "        self.attention = ScaledDotProductAttention(temperature=np.power(d_k, 0.5), attn_dropout=dropout)\n",
    "        self.layer_norm = nn.LayerNorm(d_model)\n",
    "\n",
    "        self.fc = nn.Linear(n_head * d_v, d_model)\n",
    "        \n",
    "        nn.init.xavier_normal_(self.fc.weight)\n",
    "\n",
    "        self.dropout = nn.Dropout(dropout)\n",
    "\n",
    "\n",
    "    def forward(self, q, k, v, mask=None):\n",
    "\n",
    "        d_k, d_v, n_head = self.d_k, self.d_v, self.n_head\n",
    "\n",
    "        sz_b, len_q, _ = q.size()\n",
    "        sz_b, len_k, _ = k.size()\n",
    "        sz_b, len_v, _ = v.size()\n",
    "\n",
    "        residual = q\n",
    "\n",
    "        q = self.w_qs(q).view(sz_b, len_q, n_head, d_k)\n",
    "        k = self.w_ks(k).view(sz_b, len_k, n_head, d_k)\n",
    "        v = self.w_vs(v).view(sz_b, len_v, n_head, d_v)\n",
    "\n",
    "        q = q.permute(2, 0, 1, 3).contiguous().view(-1, len_q, d_k) # (n*b) x lq x dk\n",
    "        k = k.permute(2, 0, 1, 3).contiguous().view(-1, len_k, d_k) # (n*b) x lk x dk\n",
    "        v = v.permute(2, 0, 1, 3).contiguous().view(-1, len_v, d_v) # (n*b) x lv x dv\n",
    "\n",
    "        mask = mask.repeat(n_head, 1, 1) # (n*b) x .. x ..\n",
    "        output, attn = self.attention(q, k, v, mask=mask)\n",
    "\n",
    "        output = output.view(n_head, sz_b, len_q, d_v)\n",
    "        \n",
    "        output = output.permute(1, 2, 0, 3).contiguous().view(sz_b, len_q, -1) # b x lq x (n*dv)\n",
    "\n",
    "        output = self.dropout(self.fc(output))\n",
    "        output = self.layer_norm(output + residual)\n",
    "        #output = self.layer_norm(output)\n",
    "        \n",
    "        return output, attn\n",
    "    \n",
    "\n",
    "class MapBasedMultiHeadAttention(nn.Module):\n",
    "    ''' Multi-Head Attention module '''\n",
    "    def __init__(self, n_head, d_model, d_k, d_v, dropout=0.1):\n",
    "        super().__init__()\n",
    "\n",
    "        self.n_head = n_head\n",
    "        self.d_k = d_k\n",
    "        self.d_v = d_v\n",
    "\n",
    "        self.wq_node_transform = nn.Linear(d_model, n_head * d_k, bias=False)\n",
    "        self.wk_node_transform = nn.Linear(d_model, n_head * d_k, bias=False)\n",
    "        self.wv_node_transform = nn.Linear(d_model, n_head * d_k, bias=False)\n",
    "        \n",
    "        self.layer_norm = nn.LayerNorm(d_model)\n",
    "\n",
    "        self.fc = nn.Linear(n_head * d_v, d_model)\n",
    "        \n",
    "        self.act = nn.LeakyReLU(negative_slope=0.2)\n",
    "        self.weight_map = nn.Linear(2 * d_k, 1, bias=False)\n",
    "        \n",
    "        nn.init.xavier_normal_(self.fc.weight)\n",
    "        \n",
    "        self.dropout = torch.nn.Dropout(dropout)\n",
    "        self.softmax = torch.nn.Softmax(dim=2)\n",
    "\n",
    "        self.dropout = nn.Dropout(dropout)\n",
    "\n",
    "\n",
    "    def forward(self, q, k, v, mask=None):\n",
    "        d_k, d_v, n_head = self.d_k, self.d_v, self.n_head\n",
    "        sz_b, len_q, _ = q.size()\n",
    "        sz_b, len_k, _ = k.size()\n",
    "        sz_b, len_v, _ = v.size()\n",
    "\n",
    "        residual = q\n",
    "\n",
    "        q = self.wq_node_transform(q).view(sz_b, len_q, n_head, d_k)\n",
    "        \n",
    "        k = self.wk_node_transform(k).view(sz_b, len_k, n_head, d_k)\n",
    "        \n",
    "        v = self.wv_node_transform(v).view(sz_b, len_v, n_head, d_v)\n",
    "\n",
    "        q = q.permute(2, 0, 1, 3).contiguous().view(-1, len_q, d_k) # (n*b) x lq x dk\n",
    "        q = torch.unsqueeze(q, dim=2) # [(n*b), lq, 1, dk]\n",
    "        q = q.expand(q.shape[0], q.shape[1], len_k, q.shape[3]) # [(n*b), lq, lk, dk]\n",
    "        \n",
    "        k = k.permute(2, 0, 1, 3).contiguous().view(-1, len_k, d_k) # (n*b) x lk x dk\n",
    "        k = torch.unsqueeze(k, dim=1) # [(n*b), 1, lk, dk]\n",
    "        k = k.expand(k.shape[0], len_q, k.shape[2], k.shape[3]) # [(n*b), lq, lk, dk]\n",
    "        \n",
    "        v = v.permute(2, 0, 1, 3).contiguous().view(-1, len_v, d_v) # (n*b) x lv x dv\n",
    "        \n",
    "        mask = mask.repeat(n_head, 1, 1) # (n*b) x lq x lk\n",
    "        \n",
    "        ## Map based Attention\n",
    "        #output, attn = self.attention(q, k, v, mask=mask)\n",
    "        q_k = torch.cat([q, k], dim=3) # [(n*b), lq, lk, dk * 2]\n",
    "        attn = self.weight_map(q_k).squeeze(dim=3) # [(n*b), lq, lk]\n",
    "        \n",
    "        if mask is not None:\n",
    "            attn = attn.masked_fill(mask, -1e10)\n",
    "\n",
    "        attn = self.softmax(attn) # [n * b, l_q, l_k]\n",
    "        attn = self.dropout(attn) # [n * b, l_q, l_k]\n",
    "        \n",
    "        # [n * b, l_q, l_k] * [n * b, l_v, d_v] >> [n * b, l_q, d_v]\n",
    "        output = torch.bmm(attn, v)\n",
    "        output = output.view(n_head, sz_b, len_q, d_v)\n",
    "        output = output.permute(1, 2, 0, 3).contiguous().view(sz_b, len_q, -1) # b x lq x (n*dv)\n",
    "        output = self.dropout(self.act(self.fc(output)))\n",
    "        output = self.layer_norm(output + residual)\n",
    "        return output, attn\n",
    "    \n",
    "def expand_last_dim(x, num):\n",
    "    view_size = list(x.size()) + [1]\n",
    "    expand_size = list(x.size()) + [num]\n",
    "    return x.view(view_size).expand(expand_size)\n",
    "\n",
    "\n",
    "class AttnModel(torch.nn.Module):\n",
    "    \"\"\"Attention based temporal layers\n",
    "    \"\"\"\n",
    "    def __init__(self, feat_dim, time_dim, \n",
    "                 attn_mode='prod', n_head=2, drop_out=0.1):\n",
    "        \"\"\"\n",
    "        args:\n",
    "          feat_dim: dim for the node features\n",
    "          edge_dim: dim for the temporal edge features\n",
    "          time_dim: dim for the time encoding\n",
    "          attn_mode: choose from 'prod' and 'map'\n",
    "          n_head: number of heads in attention\n",
    "          drop_out: probability of dropping a neural.\n",
    "        \"\"\"\n",
    "        super(AttnModel, self).__init__()\n",
    "        \n",
    "        self.feat_dim = feat_dim\n",
    "        self.time_dim = time_dim\n",
    "        \n",
    "        self.edge_in_dim = (feat_dim + time_dim)\n",
    "        self.model_dim = self.edge_in_dim\n",
    "        #self.edge_fc = torch.nn.Linear(self.edge_in_dim, self.feat_dim, bias=False)\n",
    "\n",
    "        self.merger = MergeLayer(self.model_dim, feat_dim, feat_dim, feat_dim)\n",
    "\n",
    "        #self.act = torch.nn.ReLU()\n",
    "        \n",
    "        assert(self.model_dim % n_head == 0)\n",
    "        self.logger = logging.getLogger(__name__)\n",
    "        self.attn_mode = attn_mode\n",
    "        \n",
    "        if attn_mode == 'prod':\n",
    "            self.multi_head_target = MultiHeadAttention(n_head, \n",
    "                                             d_model=self.model_dim, \n",
    "                                             d_k=self.model_dim // n_head, \n",
    "                                             d_v=self.model_dim // n_head, \n",
    "                                             dropout=drop_out)\n",
    "            self.logger.info('Using scaled prod attention')\n",
    "            \n",
    "        elif attn_mode == 'map':\n",
    "            self.multi_head_target = MapBasedMultiHeadAttention(n_head, \n",
    "                                             d_model=self.model_dim, \n",
    "                                             d_k=self.model_dim // n_head, \n",
    "                                             d_v=self.model_dim // n_head, \n",
    "                                             dropout=drop_out)\n",
    "            self.logger.info('Using map based attention')\n",
    "        else:\n",
    "            raise ValueError('attn_mode can only be prod or map')\n",
    "        \n",
    "        \n",
    "    def forward(self, src, src_t, seq, seq_t, seq_e, mask):\n",
    "        \"\"\"\"Attention based temporal attention forward pass\n",
    "        args:\n",
    "          src: float Tensor of shape [B, D]\n",
    "          src_t: float Tensor of shape [B, Dt], Dt == D\n",
    "          seq: float Tensor of shape [B, N, D]\n",
    "          seq_t: float Tensor of shape [B, N, Dt]\n",
    "          seq_e: float Tensor of shape [B, N, De], De == D\n",
    "          mask: boolean Tensor of shape [B, N], where the true value indicate a null value in the sequence.\n",
    "\n",
    "        returns:\n",
    "          output, weight\n",
    "\n",
    "          output: float Tensor of shape [B, D]\n",
    "          weight: float Tensor of shape [B, N]\n",
    "        \"\"\"\n",
    "\n",
    "        src_ext = torch.unsqueeze(src, dim=1) # src [B, 1, D]\n",
    "        src_e_ph = torch.zeros_like(src_ext)\n",
    "        q = torch.cat([src_ext, src_e_ph, src_t], dim=2) # [B, 1, D + De + Dt] -> [B, 1, D]\n",
    "        k = torch.cat([seq, seq_e, seq_t], dim=2) # [B, 1, D + De + Dt] -> [B, 1, D]\n",
    "        \n",
    "        mask = torch.unsqueeze(mask, dim=2) # mask [B, N, 1]\n",
    "        mask = mask.permute([0, 2, 1]) #mask [B, 1, N]\n",
    "\n",
    "        # # target-attention\n",
    "        output, attn = self.multi_head_target(q=q, k=k, v=k, mask=mask) # output: [B, 1, D + Dt], attn: [B, 1, N]\n",
    "        output = output.squeeze()\n",
    "        attn = attn.squeeze()\n",
    "\n",
    "        output = self.merger(output, src)\n",
    "        return output, attn\n",
    "    \n",
    "class TimeEncode(torch.nn.Module):\n",
    "    def __init__(self, expand_dim, factor=5):\n",
    "        super(TimeEncode, self).__init__()\n",
    "        time_dim = expand_dim\n",
    "        self.factor = factor\n",
    "        self.basis_freq = torch.nn.Parameter((torch.from_numpy(1 / 10 ** np.linspace(0, 9, time_dim))).float())\n",
    "        self.phase = torch.nn.Parameter(torch.zeros(time_dim).float())\n",
    "        \n",
    "    def forward(self, ts):\n",
    "        # ts: [N, L]\n",
    "        batch_size = ts.size(0)\n",
    "        seq_len = ts.size(1)\n",
    "        ts = ts.view(batch_size, seq_len, 1)# [N, L, 1]\n",
    "        map_ts = ts * self.basis_freq.view(1, 1, -1) # [N, L, time_dim]\n",
    "        map_ts += self.phase.view(1, 1, -1)\n",
    "        harmonic = torch.cos(map_ts)\n",
    "        return harmonic #self.dense(harmonic)\n",
    "    \n",
    "\n",
    "class GT(torch.nn.Module):\n",
    "    def __init__(self, ngh_finder, n_feat, num_communities=10, agg_method='lstm', node_dim=None, time_dim=None,\n",
    "                 num_layers=3, null_idx=0, drop_out=0.1, memory_dim=128, msg_dim=128, seq_len=None):\n",
    "        super(GT, self).__init__()\n",
    "\n",
    "        self.num_layers = num_layers \n",
    "        self.ngh_finder = ngh_finder\n",
    "        self.null_idx = null_idx\n",
    "        self.logger = logging.getLogger(__name__)\n",
    "        self.n_feat_th = torch.nn.Parameter(torch.from_numpy(n_feat.astype(np.float32)))\n",
    "\n",
    "        self.node_raw_embed = torch.nn.Embedding.from_pretrained(self.n_feat_th, padding_idx=0, freeze=True)\n",
    "\n",
    "        self.feat_dim = self.n_feat_th.shape[1]\n",
    "        self.n_feat_dim = self.feat_dim\n",
    "        self.model_dim = self.feat_dim\n",
    "        self.merge_layer = MergeLayer(self.feat_dim, self.feat_dim, self.feat_dim, self.feat_dim)\n",
    "        self.num_communities = num_communities\n",
    "        self.community_layer = CommunityLayer(input_dim=self.feat_dim,  # 输入维度为节点嵌入的维度\n",
    "            hidden_dim=self.feat_dim,  # 隐藏层维度与特征维度相同\n",
    "            num_communities=self.num_communities  # 社区数量\n",
    "        )\n",
    "        if msg_dim is not None:\n",
    "            msg_dim = self.feat_dim\n",
    "        num_nodes = self.n_feat_th.shape[0]\n",
    "        self.memory_module = MemoryModule(num_nodes, memory_dim, msg_dim)\n",
    "\n",
    "        if agg_method == 'attn':\n",
    "            self.logger.info('Aggregation uses attention model')\n",
    "            self.attn_model_list = torch.nn.ModuleList([AttnModel(self.feat_dim, \n",
    "                                                               self.feat_dim, \n",
    "                                                               self.feat_dim,\n",
    "                                                               attn_mode='prod', \n",
    "                                                               n_head=4, \n",
    "                                                               drop_out=drop_out) for _ in range(num_layers)])\n",
    "        elif agg_method == 'lstm':\n",
    "            self.attn_model_list = torch.nn.ModuleList([LSTMPool(self.feat_dim, self.feat_dim) for _ in range(num_layers)])\n",
    "        elif agg_method == 'mean':\n",
    "            self.attn_model_list = torch.nn.ModuleList([MeanPool(self.feat_dim) for _ in range(num_layers)])\n",
    "        else:\n",
    "            raise ValueError('invalid agg_method value, use attn or lstm')\n",
    "        self.time_encoder = TimeEncode(expand_dim=self.n_feat_th.shape[1])\n",
    "        self.num_communities = num_communities\n",
    "\n",
    "\n",
    "    def forward(self, src_idx_l, target_idx_l, cut_time_l, events, degrees, m, mu, num_neighbors=20):\n",
    "        device = self.n_feat_th.device\n",
    "        ct = torch.from_numpy(cut_time_l).float().to(device)\n",
    "        if ct.dim() == 1:\n",
    "            ct = ct.unsqueeze(1)         # (B, 1)\n",
    "        B, T = ct.size()\n",
    "        batch_nodes = np.unique(np.concatenate([src_idx_l, target_idx_l]))\n",
    "        batch_nodes_th = torch.from_numpy(batch_nodes).long().to(device)\n",
    "        old_memory = self.memory_module.memory[batch_nodes_th] \n",
    "\n",
    "\n",
    "        src_seq, tgt_seq = [], []\n",
    "        for t in range(T):\n",
    "            times_t = ct[:, t]\n",
    "            src_seq.append(self.tem_conv(src_idx_l, times_t, self.num_layers,\n",
    "                                          old_memory, batch_nodes_th, num_neighbors=20))\n",
    "            tgt_seq.append(self.tem_conv(target_idx_l, times_t, self.num_layers,\n",
    "                                          old_memory, batch_nodes_th, num_neighbors=20))\n",
    "\n",
    "\n",
    "        src_embed = torch.stack(src_seq, dim=1)  # (B, T, D)\n",
    "        tgt_embed = torch.stack(tgt_seq, dim=1)  # (B, T, D)\n",
    "        _, src_assignments = self.community_layer(src_embed)      # 现在是 (B_src, T, K)\n",
    "        _, tgt_assignments = self.community_layer(tgt_embed)   # 现在是 (B_tgt, T, K)\n",
    "        assignments = torch.cat([src_assignments, tgt_assignments], dim=0) \n",
    "        mod_loss = l_modularity_loss(assignments, events, degrees, m, mu)\n",
    "        return mod_loss\n",
    "    \n",
    "\n",
    "    \n",
    "    def tem_conv(self, src_idx_l, cut_time_l, curr_layers, old_memory, batch_nodes_th, num_neighbors=20):\n",
    "        assert(curr_layers >= 0)\n",
    "        device = self.n_feat_th.device\n",
    "        batch_size = len(src_idx_l)\n",
    "        \n",
    "        # 在 tem_conv 开头，替换这一行：\n",
    "        #cut_time_l_th = torch.from_numpy(cut_time_l).float().to(device)\n",
    "        #cut_time_l_th = torch.from_numpy(cut_time_l).float().to(device)\n",
    "        #cut_time_l_th = torch.unsqueeze(cut_time_l_th, dim=1)\n",
    "        # 类型转换\n",
    "        if isinstance(cut_time_l, torch.Tensor):\n",
    "            cut_time_l_th = cut_time_l.float().to(device)\n",
    "        elif isinstance(cut_time_l, np.ndarray):\n",
    "            cut_time_l_th = torch.from_numpy(cut_time_l).float().to(device)\n",
    "        else:\n",
    "            raise TypeError(f\"Unsupported type for cut_time_l: {type(cut_time_l)}\")\n",
    "\n",
    "        # 保证至少是 (B, 1)\n",
    "        if cut_time_l_th.dim() == 1:\n",
    "            cut_time_l_th = cut_time_l_th.unsqueeze(1)  \n",
    "        elif cut_time_l_th.dim() != 2:\n",
    "            raise ValueError(f\"cut_time_l_th must be 1D or 2D, got {cut_time_l_th.dim()}D\")\n",
    "\n",
    "        # 然后再\n",
    "        src_node_t_embed = self.time_encoder(torch.zeros_like(cut_time_l_th))\n",
    "                            \n",
    "\n",
    "        src_node_batch_th = torch.from_numpy(src_idx_l).long().to(device)\n",
    "        \n",
    "        # query node always has the start time -> time span == 0\n",
    "        #src_node_t_embed = self.time_encoder(torch.zeros_like(cut_time_l_th))\n",
    "        src_node_feat = self.node_raw_embed(src_node_batch_th)\n",
    "        \n",
    "        if curr_layers == 0:\n",
    "            return src_node_feat\n",
    "        else:\n",
    "            src_node_conv_feat = self.tem_conv(\n",
    "                src_idx_l, cut_time_l, curr_layers - 1,\n",
    "                 old_memory, batch_nodes_th,num_neighbors)\n",
    "            \n",
    "            print(num_neighbors)\n",
    "            src_ngh_node_batch, src_ngh_eidx_batch, src_ngh_t_batch = self.ngh_finder.get_temporal_neighbor( \n",
    "                                                                    src_idx_l, \n",
    "                                                                    cut_time_l, \n",
    "                                                                    num_neighbors=num_neighbors)\n",
    "\n",
    "            src_ngh_node_batch_th = torch.from_numpy(src_ngh_node_batch).long().to(device)\n",
    "            src_ngh_eidx_batch = torch.from_numpy(src_ngh_eidx_batch).long().to(device)\n",
    "            \n",
    "            #src_ngh_t_batch_delta = cut_time_l[:, np.newaxis] - src_ngh_t_batch\n",
    "            src_ngh_t_batch_th = torch.from_numpy(src_ngh_t_batch).float().to(device)\n",
    "            if cut_time_l_th.dim() == 1:\n",
    "                cut_time_l_th = cut_time_l_th.unsqueeze(1)\n",
    "            elif cut_time_l_th.dim() != 2:\n",
    "                raise ValueError(f\"cut_time_l_th must be 1D or 2D, got {cut_time_l_th.dim()}D\")\n",
    "            # 3. compute delta in torch (broadcasting):\n",
    "            src_ngh_t_batch_delta_th = cut_time_l_th - src_ngh_t_batch_th    # Tensor (B, num_neighbors)\n",
    "            # 4. flatten for recursive call:\n",
    "            src_ngh_t_batch_flat = src_ngh_t_batch_delta_th.flatten()\n",
    "            # get previous layer's node features\n",
    "            src_ngh_node_batch_flat = src_ngh_node_batch.flatten() #reshape(batch_size, -1)\n",
    "            #src_ngh_t_batch_flat = src_ngh_t_batch.flatten() #reshape(batch_size, -1)  \n",
    "            src_ngh_node_conv_feat = self.tem_conv(src_ngh_node_batch_flat, \n",
    "                                                   src_ngh_t_batch_flat,\n",
    "                                                   old_memory, batch_nodes_th,\n",
    "                                                   curr_layers=curr_layers - 1, \n",
    "                                                   num_neighbors=num_neighbors)\n",
    "            src_ngh_feat = src_ngh_node_conv_feat.view(batch_size, num_neighbors, -1)\n",
    "            \n",
    "            # get edge time features and node features\n",
    "            src_ngh_t_embed = self.time_encoder(src_ngh_t_batch_th)\n",
    "\n",
    "            # attention aggregation\n",
    "            mask = src_ngh_node_batch_th == 0\n",
    "            attn_m = self.attn_model_list[curr_layers - 1]\n",
    "                        \n",
    "            local, weight = attn_m(src_node_conv_feat, \n",
    "                                src_node_t_embed,\n",
    "                                src_ngh_feat,\n",
    "                                src_ngh_t_embed,\n",
    "                                mask)\n",
    "            \n",
    "            idx_map = {nid: i for i, nid in enumerate(batch_nodes_th.cpu().numpy())}\n",
    "            positions = torch.tensor([idx_map[n] for n in src_idx_l],\n",
    "                                     device=device, dtype=torch.long)\n",
    "            # 2) 取出对应的旧 memory\n",
    "            old_mem = old_memory[positions]  # (B, memory_dim)\n",
    "            # 3) GRUCell 更新\n",
    "            new_mem = self.memory_module.gru(local, old_mem)  # (B, memory_dim)\n",
    "            # 4) 写回全局 memory buffer\n",
    "            self.memory_module.memory[batch_nodes_th[positions]] = new_mem\n",
    "\n",
    "            # 最后返回聚合特征 local 以及（可选）更新后的 memory new_mem\n",
    "            return local  \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "\n",
    "n_feat = np.load('node_embeddings.npy')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "g_df = pd.read_csv(\"data/SBM-r1-0-reindexed.csv\")\n",
    "src_l = g_df.u.values\n",
    "dst_l = g_df.v.values\n",
    "max_idx = np.max(np.concatenate([src_l, dst_l]))\n",
    "e_idx_l = g_df.idx.values\n",
    "ts_l = g_df.timestamp.values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_total_degree(df: pd.DataFrame) -> dict:\n",
    "    \"\"\"\n",
    "    计算每个节点的总度数，返回一个字典 {node_id: degree}\n",
    "    \"\"\"\n",
    "    from collections import defaultdict\n",
    "\n",
    "    degree_dict = defaultdict(int)\n",
    "\n",
    "    # 遍历每条边，更新两端节点的度\n",
    "    for _, row in df.iterrows():\n",
    "        degree_dict[row['u']] += 1\n",
    "        degree_dict[row['v']] += 1  # 无向图\n",
    "\n",
    "    return dict(degree_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10\n",
      "Epoch 0\n",
      "k: 0\n",
      "tensor([ 0,  1,  2,  3,  4,  5,  6,  7,  8,  9, 10, 11, 12, 13, 14, 15, 16, 17,\n",
      "        18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35,\n",
      "        36, 37, 38, 39, 40, 41, 42, 43, 44, 45, 46, 47, 48, 49, 50, 51, 52, 53,\n",
      "        54, 55, 56, 57, 58, 59, 60, 61, 62, 63, 64, 65, 66, 67, 68, 69, 70, 71,\n",
      "        72, 73, 74, 75, 76, 77, 78, 79, 80, 81, 82, 83, 84, 85, 86, 87, 88],\n",
      "       device='mps:0')\n"
     ]
    },
    {
     "ename": "TypeError",
     "evalue": "only integer tensors of a single element can be converted to an index",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[81], line 60\u001b[0m\n\u001b[1;32m     58\u001b[0m events \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39mtensor(events\u001b[38;5;241m.\u001b[39mvalues, dtype\u001b[38;5;241m=\u001b[39mtorch\u001b[38;5;241m.\u001b[39mlong)\n\u001b[1;32m     59\u001b[0m optimizer\u001b[38;5;241m.\u001b[39mzero_grad()\n\u001b[0;32m---> 60\u001b[0m loss \u001b[38;5;241m=\u001b[39m \u001b[43mtgan\u001b[49m\u001b[43m(\u001b[49m\u001b[43msrc_l_cut\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdst_l_cut\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mts_l_cut\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mevents\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdegrees\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mm\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmu\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m0.5\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mnum_neighbors\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m20\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[1;32m     61\u001b[0m loss\u001b[38;5;241m.\u001b[39mbackward()\n\u001b[1;32m     62\u001b[0m optimizer\u001b[38;5;241m.\u001b[39mstep()\n",
      "File \u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.9/lib/python3.9/site-packages/torch/nn/modules/module.py:1532\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1530\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[1;32m   1531\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m-> 1532\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.9/lib/python3.9/site-packages/torch/nn/modules/module.py:1541\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1536\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1537\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1538\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1539\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1540\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1541\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1543\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m   1544\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "Cell \u001b[0;32mIn[77], line 418\u001b[0m, in \u001b[0;36mGT.forward\u001b[0;34m(self, src_idx_l, target_idx_l, cut_time_l, events, degrees, m, mu, num_neighbors)\u001b[0m\n\u001b[1;32m    416\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m t \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(T):\n\u001b[1;32m    417\u001b[0m     times_t \u001b[38;5;241m=\u001b[39m ct[:, t]\n\u001b[0;32m--> 418\u001b[0m     src_seq\u001b[38;5;241m.\u001b[39mappend(\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtem_conv\u001b[49m\u001b[43m(\u001b[49m\u001b[43msrc_idx_l\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtimes_t\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mnum_layers\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    419\u001b[0m \u001b[43m                                  \u001b[49m\u001b[43mold_memory\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mbatch_nodes_th\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mnum_neighbors\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m20\u001b[39;49m\u001b[43m)\u001b[49m)\n\u001b[1;32m    420\u001b[0m     tgt_seq\u001b[38;5;241m.\u001b[39mappend(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mtem_conv(target_idx_l, times_t, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mnum_layers,\n\u001b[1;32m    421\u001b[0m                                   old_memory, batch_nodes_th, num_neighbors\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m20\u001b[39m))\n\u001b[1;32m    424\u001b[0m src_embed \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39mstack(src_seq, dim\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m1\u001b[39m)  \u001b[38;5;66;03m# (B, T, D)\u001b[39;00m\n",
      "Cell \u001b[0;32mIn[77], line 470\u001b[0m, in \u001b[0;36mGT.tem_conv\u001b[0;34m(self, src_idx_l, cut_time_l, curr_layers, old_memory, batch_nodes_th, num_neighbors)\u001b[0m\n\u001b[1;32m    468\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m src_node_feat\n\u001b[1;32m    469\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m--> 470\u001b[0m     src_node_conv_feat \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtem_conv\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    471\u001b[0m \u001b[43m        \u001b[49m\u001b[43msrc_idx_l\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcut_time_l\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcurr_layers\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m-\u001b[39;49m\u001b[43m \u001b[49m\u001b[38;5;241;43m1\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[1;32m    472\u001b[0m \u001b[43m        \u001b[49m\u001b[43mnum_neighbors\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mold_memory\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mbatch_nodes_th\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    474\u001b[0m     \u001b[38;5;28mprint\u001b[39m(num_neighbors)\n\u001b[1;32m    475\u001b[0m     src_ngh_node_batch, src_ngh_eidx_batch, src_ngh_t_batch \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mngh_finder\u001b[38;5;241m.\u001b[39mget_temporal_neighbor( \n\u001b[1;32m    476\u001b[0m                                                             src_idx_l, \n\u001b[1;32m    477\u001b[0m                                                             cut_time_l, \n\u001b[1;32m    478\u001b[0m                                                             num_neighbors\u001b[38;5;241m=\u001b[39mnum_neighbors)\n",
      "Cell \u001b[0;32mIn[77], line 475\u001b[0m, in \u001b[0;36mGT.tem_conv\u001b[0;34m(self, src_idx_l, cut_time_l, curr_layers, old_memory, batch_nodes_th, num_neighbors)\u001b[0m\n\u001b[1;32m    470\u001b[0m src_node_conv_feat \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mtem_conv(\n\u001b[1;32m    471\u001b[0m     src_idx_l, cut_time_l, curr_layers \u001b[38;5;241m-\u001b[39m \u001b[38;5;241m1\u001b[39m,\n\u001b[1;32m    472\u001b[0m     num_neighbors, old_memory, batch_nodes_th)\n\u001b[1;32m    474\u001b[0m \u001b[38;5;28mprint\u001b[39m(num_neighbors)\n\u001b[0;32m--> 475\u001b[0m src_ngh_node_batch, src_ngh_eidx_batch, src_ngh_t_batch \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mngh_finder\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget_temporal_neighbor\u001b[49m\u001b[43m(\u001b[49m\u001b[43m \u001b[49m\n\u001b[1;32m    476\u001b[0m \u001b[43m                                                        \u001b[49m\u001b[43msrc_idx_l\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\n\u001b[1;32m    477\u001b[0m \u001b[43m                                                        \u001b[49m\u001b[43mcut_time_l\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\n\u001b[1;32m    478\u001b[0m \u001b[43m                                                        \u001b[49m\u001b[43mnum_neighbors\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mnum_neighbors\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    480\u001b[0m src_ngh_node_batch_th \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39mfrom_numpy(src_ngh_node_batch)\u001b[38;5;241m.\u001b[39mlong()\u001b[38;5;241m.\u001b[39mto(device)\n\u001b[1;32m    481\u001b[0m src_ngh_eidx_batch \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39mfrom_numpy(src_ngh_eidx_batch)\u001b[38;5;241m.\u001b[39mlong()\u001b[38;5;241m.\u001b[39mto(device)\n",
      "File \u001b[0;32m~/Desktop/research/detect/graph.py:99\u001b[0m, in \u001b[0;36mNeighborFinder.get_temporal_neighbor\u001b[0;34m(self, src_idx_l, cut_time_l, num_neighbors)\u001b[0m\n\u001b[1;32m     90\u001b[0m \u001b[38;5;250m\u001b[39m\u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m     91\u001b[0m \u001b[38;5;124;03mParams\u001b[39;00m\n\u001b[1;32m     92\u001b[0m \u001b[38;5;124;03m------\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m     95\u001b[0m \u001b[38;5;124;03mnum_neighbors: int\u001b[39;00m\n\u001b[1;32m     96\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m     97\u001b[0m \u001b[38;5;28;01massert\u001b[39;00m(\u001b[38;5;28mlen\u001b[39m(src_idx_l) \u001b[38;5;241m==\u001b[39m \u001b[38;5;28mlen\u001b[39m(cut_time_l))\n\u001b[0;32m---> 99\u001b[0m out_ngh_node_batch \u001b[38;5;241m=\u001b[39m \u001b[43mnp\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mzeros\u001b[49m\u001b[43m(\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mlen\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43msrc_idx_l\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mnum_neighbors\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241m.\u001b[39mastype(np\u001b[38;5;241m.\u001b[39mint32)\n\u001b[1;32m    100\u001b[0m out_ngh_t_batch \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39mzeros((\u001b[38;5;28mlen\u001b[39m(src_idx_l), num_neighbors))\u001b[38;5;241m.\u001b[39mastype(np\u001b[38;5;241m.\u001b[39mfloat32)\n\u001b[1;32m    101\u001b[0m out_ngh_eidx_batch \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39mzeros((\u001b[38;5;28mlen\u001b[39m(src_idx_l), num_neighbors))\u001b[38;5;241m.\u001b[39mastype(np\u001b[38;5;241m.\u001b[39mint32)\n",
      "\u001b[0;31mTypeError\u001b[0m: only integer tensors of a single element can be converted to an index"
     ]
    }
   ],
   "source": [
    "import math\n",
    "import torch\n",
    "\n",
    "from utils import *\n",
    "from graph import *\n",
    "### Model initialize\n",
    "NUM_LAYER = 2\n",
    "AGG_METHOD = \"lstm\"\n",
    "device = torch.device('mps')\n",
    "\n",
    "adj_list = [[] for _ in range(0, max_idx + 1)]\n",
    "for src, dst, eidx, ts in zip(src_l, dst_l, e_idx_l, ts_l):\n",
    "    adj_list[src].append((dst, eidx, ts))\n",
    "    adj_list[dst].append((src, eidx, ts))\n",
    "train_ngh_finder = NeighborFinder(adj_list, uniform=True)\n",
    "\n",
    "\n",
    "tgan = GT(train_ngh_finder, n_feat,\n",
    "            num_layers=NUM_LAYER, agg_method=AGG_METHOD, \n",
    "            drop_out=0.1, node_dim=64, time_dim=64)\n",
    "\n",
    "tgan = tgan.to(device)\n",
    "\n",
    "NUM_NEIGHBORS = 20\n",
    "LEARNING_RATE = 0.00001\n",
    "BATCH_SIZE = 100\n",
    "\n",
    "optimizer = torch.optim.Adam(tgan.parameters(), lr=LEARNING_RATE)\n",
    "\n",
    "# --- 训练主循环 ---\n",
    "\n",
    "NUM_EPOCH = 50\n",
    "num_instance = len(src_l)\n",
    "idx_list = np.arange(num_instance)\n",
    "num_batch = math.ceil(num_instance / BATCH_SIZE)\n",
    "print(num_batch)\n",
    "\n",
    "loss_list = []\n",
    "for epoch in range(NUM_EPOCH):\n",
    "    tgan.ngh_finder = train_ngh_finder\n",
    "    tgan = tgan.train()\n",
    "\n",
    "    total_loss = 0\n",
    "    batch_count = 0\n",
    "\n",
    "    print(f'Epoch {epoch}')\n",
    "    for k in range(num_batch):\n",
    "        print(\"k:\",k)\n",
    "        s_idx = k * BATCH_SIZE\n",
    "        e_idx = min(num_instance - 1, s_idx + BATCH_SIZE)\n",
    "        src_l_cut, dst_l_cut = src_l[s_idx:e_idx], dst_l[s_idx:e_idx]\n",
    "        ts_l_cut = ts_l[s_idx:e_idx]\n",
    "        \n",
    "        size = len(src_l_cut)\n",
    "        events = g_df[s_idx:e_idx]\n",
    "        m = events.shape[0]\n",
    "        degrees = compute_total_degree(events)\n",
    "        events = torch.tensor(events.values, dtype=torch.long)\n",
    "        optimizer.zero_grad()\n",
    "        loss = tgan(src_l_cut, dst_l_cut, ts_l_cut, events, degrees, m, mu=0.5, num_neighbors=20)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        total_loss += loss.item()\n",
    "        batch_count += 1\n",
    "\n",
    "    \n",
    "    avg_loss = total_loss / batch_count\n",
    "    loss_list.append(avg_loss)\n",
    "    print(f\"Epoch {epoch}: Average Loss = {avg_loss:.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "plt.plot(loss_list)\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
